{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1c8ca8",
   "metadata": {},
   "source": [
    "# Scraping Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2e4c3",
   "metadata": {},
   "source": [
    "## Converting Json to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSON data into DataFrame\n",
    "with open('celeb_heights.com.json', encoding='utf-8') as f:\n",
    "    data = pd.read_json(f)\n",
    "\n",
    "# Extract names\n",
    "names = data['name'].tolist()\n",
    "\n",
    "# Define CSV file path\n",
    "csv_file = 'names.csv'\n",
    "\n",
    "# Save names to CSV file\n",
    "data = pd.DataFrame({'Name': names})\n",
    "data.to_csv(csv_file, index=False)\n",
    "\n",
    "print('Names saved to', csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d3511",
   "metadata": {},
   "source": [
    "## Scraping From Wikipedia Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2fe57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_American_film_actresses\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the div with the specified class\n",
    "div = soup.select(\".div-col\")\n",
    "final=[]\n",
    "for d in div:\n",
    "# Find all the list items within the div\n",
    "    list_items = d.find_all(\"li\")\n",
    "    # Extract the names from the list items\n",
    "    names = [item.find(\"a\").get_text(strip=True) for item in list_items]\n",
    "    # Specify the filename for the CSV file\n",
    "    print(names)\n",
    "    final.append(names)\n",
    "filename = \"americanactress.csv\"\n",
    "print(final)\n",
    "    # Open the CSV file in write mode and write the data\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "        # Write the header to the CSV file\n",
    "    writer.writerow([\"Name\"])\n",
    "\n",
    "        # Write each name to the CSV file as a row\n",
    "    writer.writerows([[name] for name in final])\n",
    "\n",
    "print(f\"Names extracted successfully and saved to '{filename}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe36812",
   "metadata": {},
   "source": [
    "# MechanicalSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13862c78",
   "metadata": {},
   "source": [
    "## Scraping using IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mechanicalsoup,random\n",
    "import json\n",
    "headers={\n",
    "        \"user-agent\" : random.choice([\n",
    "               \"Mozilla/5.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/537.51.1 (KHTML, like Gecko) Version/8.0 Mobile/11A465 Safari/9537.53\",\n",
    "              \"Mozilla/5.0 (iPhone; CPU iPhone OS 15_7 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) GSA/98.0.300355889 Mobile/15E148 Safari/604.1\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) GSA/270.0.542728515 Mobile/15E148 Safari/604.1\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 it.fanpage.rn.ios/3.10.9\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 MobileIron/2.18.1 Version/16.5.1 Safari/605.1.15\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_1_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 MobileIron/2.18.1 Version/16.1.2 Safari/605.1.15\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 12_4_8 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/81.0.4044.113 Mobile/16G201 Safari/604.1\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 12_5_7 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.5 Mobile/15E148 Safari/604.1 RDDocuments/7.5.4.747\",\n",
    "      \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/87.0.4280.163 Mobile/15E148 Safari/604.1\",\n",
    "\n",
    "            ]),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "    }\n",
    "browser = mechanicalsoup.StatefulBrowser()\n",
    "url = 'https://www.imdb.com/name/nm0000002/bio/?ref_=nm_ov_bio_sm'\n",
    "browser.open(url, headers=headers)\n",
    "soup = browser.get_current_page()\n",
    "\n",
    "# Find the h2 tag with the attribute 'data-testid=\"subtitle\"'\n",
    "h2_tag = soup.select_one('h2[data-testid=\"subtitle\"]')\n",
    "\n",
    "# Extract the text content of the h2 tag\n",
    "if h2_tag:\n",
    "    subtitle = h2_tag.text\n",
    "    print(\"Name:\", subtitle)\n",
    "else:\n",
    "    print(\"Subtitle not found.\")\n",
    "\n",
    "height_li = soup.find('li', id='height')\n",
    "\n",
    "# Extract the height value\n",
    "if height_li:\n",
    "    height_div = height_li.find('div', class_='ipc-html-content-inner-div')\n",
    "    height_text = height_div.get_text(strip=True)\n",
    "    print(\"Height:\", height_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4968c",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e30500",
   "metadata": {},
   "source": [
    "## Scraping of famouspeople"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver (make sure you have the appropriate browser driver installed)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = \"https://www.thefamouspeople.com/actress.php\"\n",
    "driver.get(url)\n",
    "\n",
    "# Scroll to the bottom of the page\n",
    "def scroll_to_bottom():\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "# Find and click the element with class \"loading-bar\"\n",
    "def click_loading_bar():\n",
    "    loading_bar = driver.find_element(By.CSS_SELECTOR, \"div.loading-bar\")\n",
    "    loading_bar.click()\n",
    "\n",
    "# Wait for the page to load\n",
    "def wait_for_page_to_load():\n",
    "    WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.ptitle-internal a.tileLink\")))\n",
    "\n",
    "# Perform the scrolling and extraction\n",
    "scroll_to_bottom()\n",
    "click_loading_bar()\n",
    "wait_for_page_to_load()\n",
    "\n",
    "# Extract the information you need from the scrolled page\n",
    "# actor_elements = driver.find_elements(By.CSS_SELECTOR, \"div.ptitle-internal a.tileLink\")\n",
    "# for actor_element in actor_elements:\n",
    "#     name = actor_element.text.strip()\n",
    "#     print(name)\n",
    "\n",
    "# Repeat the process\n",
    "count=0\n",
    "actress_names=[]\n",
    "while True:\n",
    "    scroll_to_bottom()\n",
    "    click_loading_bar()\n",
    "    wait_for_page_to_load()\n",
    "\n",
    "    # Extract the information from the newly loaded content\n",
    "    actor_elements = driver.find_elements(By.CSS_SELECTOR, \"div.ptitle-internal a.tileLink\")\n",
    "    for actor_element in actor_elements:\n",
    "        name = actor_element.text.strip()\n",
    "        if name not in actress_names:\n",
    "            count+=1\n",
    "            print(f\"{count} elements are sucessfully pushed to the fresh array\")\n",
    "            actress_names.append(name)\n",
    "        print(name)\n",
    "        \n",
    "    # Check if the end of the page is reached\n",
    "    if len(actor_elements) == 0:\n",
    "        break\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc416af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
